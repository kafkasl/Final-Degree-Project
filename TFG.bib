@article{Adler2015,
abstract = {We present a linear-time subspace clustering approach that combines sparse representations and bipartite graph modeling. The signals are modeled as drawn from a union of low-dimensional subspaces, and each signal is represented by a sparse combination of basis elements, termed atoms, which form the columns of a dictionary matrix. The sparse representation coefficients are arranged in a sparse affinity matrix, which defines a bipartite graph of two disjoint sets: 1) atoms and 2) signals. Subspace clustering is obtained by applying low-complexity spectral bipartite graph clustering that exploits the small number of atoms for complexity reduction. The complexity of the proposed approach is linear in the number of signals, thus it can rapidly cluster very large data collections. Performance evaluation of face clustering and temporal video segmentation demonstrates comparable clustering accuracies to state-of-the-art at a significantly lower computational load.},
author = {Adler, Amir and Elad, Michael and Hel-Or, Yacov},
doi = {10.1109/TNNLS.2014.2374631},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
pages = {1--1},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Linear-Time Subspace Clustering via Bipartite Graph Modeling}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84923238491\&partnerID=tZOtx3y1},
year = {2015}
}
@article{Armbrust2010,
author = {Armbrust, Michael and Stoica, Ion and Zaharia, Matei and Fox, Armando and Griffith, Rean and Joseph, Anthony D. and Katz, Randy and Konwinski, Andy and Lee, Gunho and Patterson, David and Rabkin, Ariel},
doi = {10.1145/1721654.1721672},
file = {:home/kurtz/Documents/Mendeley/Armbrust et al. - 2010 - A view of cloud computing.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = apr,
number = {4},
pages = {50},
publisher = {ACM},
title = {{A view of cloud computing}},
url = {http://dl.acm.org/ft\_gateway.cfm?id=1721672\&type=html},
volume = {53},
year = {2010}
}
@article{Ayech2015,
abstract = {Terahertz imaging is a novel imaging modality that has been used with great potential in many applications. Due to its specific properties, the segmentation of this type of images makes possible the discrimination of diverse regions within a sample. Among many segmentation methods, k-means clustering is considered as one of the most popular techniques. However, it is known that k-means is especially sensitive to initial starting centers. In this paper, we propose an original version of k-means for the segmentation of Terahertz images, called ranked-k-means, which is essentially less sensitive to the initialization of the centers. We present the ranked set sampling design and explain how to reformulate the k-means technique under the ranked sample to estimate the expected centers as well as the clustering of the observed data. Our clustering approach is tested on various real Terahertz images. Experimental results show that k-means clustering based on ranked set sampling is more efficient than other clustering techniques such as the k-means based on the fundamental sampling design simple random sampling technique, the standard k-means and the k-means based on the Bradley refinement of initial centers. Crown},
author = {Ayech, Mohamed Walid and Ziou, Djemel},
doi = {10.1016/j.eswa.2014.11.050},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Ranked set sampling,Segmentation,Simple random sampling,Terahertz imaging,k-means},
month = apr,
number = {6},
pages = {2959--2974},
publisher = {Elsevier Ltd},
title = {{Segmentation of Terahertz imaging using k-means clustering based on ranked set sampling}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417414007490},
volume = {42},
year = {2015}
}
@article{Badia2003,
author = {Badia, R. M. and Labarta, J. and Sirvent, R. and Perez, J. M. and Cela, J. M. and Grima, R.},
journal = {Journal of Grid Computing},
number = {2},
pages = {151--170},
title = {{Programming Grid Applications with GRID superscalar}},
volume = {1},
year = {2003}
}
@inproceedings{Burca2014,
abstract = {Cluster analysis is a multivariate method used in many fields in order to group a population of objects based on a set of computed variables into a number of different groups, so that similar objects be assigned to the same group. Discriminant analysis represents a technique of supervised recognition of forms used to determine which variables are the best predictors of the classification of objects belonging to a population into predetermined clusters. In this paper we will use discriminant analysis to classify the insurance companies that operated on the Romanian insurance market in 2012, taking in consideration a number of eight variables which are highly relevant for this industry. Before proceeding to discriminant analysis, we performed cluster analysis on the original data in order to identify classes that result from the data.},
author = {Burca, Ana Maria and Batr\^{\i}nca, Ghiorghe},
booktitle = {Vision 2020: Sustainable Growth, Economic Development, and Global Competitiveness - Proceedings of the 23rd International Business Information Management Association Conference, IBIMA 2014},
isbn = {9780986041921},
keywords = {Classifier,Cluster analysis,Discriminant analysis,Insurance market},
pages = {817--824},
publisher = {International Business Information Management Association, IBIMA},
title = {{Application of cluster and discriminant analysis on romanian insurance market}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84906248178\&partnerID=tZOtx3y1},
volume = {1},
year = {2014}
}
@article{Chan2014,
abstract = {The purpose of this study is to identify academically at-risk students in first-semester general chemistry using affective characteristics via cluster analysis. Through the clustering of six preselected affective variables, three distinct affective groups were identified: low (at-risk), medium, and high. Students in the low affective group reported lower scores on intellectual accessibility, emotional satisfaction, math self-concept, chemistry self-concept, and self-efficacy and a higher score on test anxiety. Significant differences were found on exam performance between the high and low affective groups with the high affective group performing significantly better than the low affective group. In terms of value beliefs, expectancy beliefs, and metacognitive self-regulation, differences were found between the high and low groups as well. These findings provide instructors an efficient way of identifying and reaching out to at-risk students early in the semester, as well as gaining a better understanding of the affective profile found in general chemistry.},
author = {Chan, Julia Y. K. and Bauer, Christopher F.},
doi = {10.1021/ed500170x},
issn = {0021-9584},
journal = {Journal of Chemical Education},
keywords = {Administrative Issues,Chemical Education Research,First-Year Undergraduate/General,High School/Introductory Chemistry,Learning Theories,Testing/Assessment},
month = sep,
number = {9},
pages = {1417--1425},
publisher = {American Chemical Society},
title = {{Identifying At-Risk Students in General Chemistry via Cluster Analysis of Affective Characteristics}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84922331781\&partnerID=tZOtx3y1},
volume = {91},
year = {2014}
}
@article{Cortes2007,
abstract = {Cluster analysis, a classification technique used to group data in many fields, is developed here as a tool to study magma mixing and mixed crystal populations in volcanic rocks. The method is based on the quantification of the chemical degree of similarity among populations of mineral chemistry data, which allows identification of discrete clusters. In order to apply the technique for the particular problem of mixed crystal populations, the mineral chemistry of a given crystalline phase is represented by a vector with "n" coordinates, in which each coordinate is a real number that represents the amount of a given component in cations per formula unit present in the phase. These vectors are in a set, which is a subset of Rn, the real vector space of n dimensions. Because mineral chemistry data are a particular case of compositional data (i.e. the components sum to a constant value, usually 100\% or the numbers of cations per formula unit), the conventional Euclidean distance cannot be used to quantify how similar the data are, in order to apply cluster analysis. To avoid this predicament, Aitchison's metric is proposed to measure similarities instead. Here, average linkage, a hierarchical clustering technique, combined with the Aitchison metric and stoichiometrical constraints, is applied to mineral chemistry data. This approach is evaluated using well-characterized lava samples from the Vancori period of activity (26-13.8 ky) of Stromboli volcano, Italy, in which magma mixing has been identified between a basaltic andesite-latite, hosted in the magma chamber and a less evolved basaltic recharge magma. The results are in agreement with previous interpretations of magma mixing, which validates the use of the cluster analysis technique in the context of magma mixing relationships, and opens the possibility to expand this methodology to other aspects of igneous petrology. © 2007 Elsevier B.V. All rights reserved.},
author = {Cort\'{e}s, Joaqu\'{\i}n A. and Palma, Jos\'{e} Luis and Wilson, Marjorie},
doi = {10.1016/j.jvolgeores.2007.05.018},
issn = {03770273},
journal = {Journal of Volcanology and Geothermal Research},
keywords = {cluster analysis,compositional data,crystal populations,magma mixing,mineral chemistry},
month = sep,
number = {3-4},
pages = {163--188},
title = {{Deciphering magma mixing: The application of cluster analysis to the mineral chemistry of crystal populations}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34547842243\&partnerID=tZOtx3y1},
volume = {165},
year = {2007}
}
@article{Dalcin2008,
abstract = {MPI for Python provides bindings of the message passing interface (MPI) standard for the Python programming language and allows any Python program to exploit multiple processors. In its first release, MPI for Python was constructed on top of the MPI-1 specification defining an object-oriented interface that closely followed the MPI-2 C++ bindings, and provided support for communications of general Python objects. In the latest release, this package is improved to enable direct blocking/non-blocking communication of numeric arrays, and to support almost all MPI-2 features. Improvements in communication performance have been tested in a Beowulf class cluster. Results showed a negligible overhead in comparison to compiled C code. MPI for Python is open source and available for download on the web (http://mpi4py.scipy.org/).},
author = {Dalc\'{\i}n, Lisandro and Paz, Rodrigo and Storti, Mario and D’El\'{\i}a, Jorge},
doi = {10.1016/j.jpdc.2007.09.005},
issn = {07437315},
journal = {Journal of Parallel and Distributed Computing},
keywords = {High-level languages,MPI,Message passing,Parallel Python},
month = may,
number = {5},
pages = {655--662},
title = {{MPI for Python: Performance improvements and MPI-2 extensions}},
url = {http://www.sciencedirect.com/science/article/pii/S0743731507001712},
volume = {68},
year = {2008}
}
@inproceedings{Foster2008,
author = {Foster, Ian and Zhao, Yong and Raicu, Ioan and Lu, Shiyong},
booktitle = {2008 Grid Computing Environments Workshop},
doi = {10.1109/GCE.2008.4738445},
isbn = {978-1-4244-2860-1},
keywords = {Cloud computing,Computer science,Computer vision,Costs,Distributed computing,Economies of scale,Grid computing,Laboratories,Large-scale systems,Standards organizations,cloud computing,cluster computing,distributed system,grid computing,utility computing},
language = {English},
month = nov,
pages = {1--10},
publisher = {IEEE},
title = {{Cloud Computing and Grid Computing 360-Degree Compared}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4738445},
year = {2008}
}
@article{Gil2014,
abstract = {Cluster analysis is becoming a relevant tool in structural bioinformatics. It allows analyzing large conformational ensembles in order to extract features or diminish redundancy, or just as a first step for other methods. Unfortunately, the successfulness of this analysis strongly depends on the data set traits, the chosen algorithm, and its parameters, which can lead to poor or even erroneous results not easily detected. In order to overcome this problem, we have developed pyProCT, a Python open source cluster analysis toolkit specially designed to be used with ensembles of biomolecule conformations. pyProCT implements an automated protocol to choose the clustering algorithm and parameters that produce the best results for a particular data set. It offers different levels of customization according to users? expertise. Moreover, pyProCT has been designed as a collection of interchangeable libraries, making it easier to reuse it as part of other programs.
Cluster analysis is becoming a relevant tool in structural bioinformatics. It allows analyzing large conformational ensembles in order to extract features or diminish redundancy, or just as a first step for other methods. Unfortunately, the successfulness of this analysis strongly depends on the data set traits, the chosen algorithm, and its parameters, which can lead to poor or even erroneous results not easily detected. In order to overcome this problem, we have developed pyProCT, a Python open source cluster analysis toolkit specially designed to be used with ensembles of biomolecule conformations. pyProCT implements an automated protocol to choose the clustering algorithm and parameters that produce the best results for a particular data set. It offers different levels of customization according to users? expertise. Moreover, pyProCT has been designed as a collection of interchangeable libraries, making it easier to reuse it as part of other programs.},
author = {Gil, V\'{\i}ctor A. and Guallar, V\'{\i}ctor},
doi = {10.1021/ct500306s},
issn = {1549-9618},
journal = {Journal of Chemical Theory and Computation},
month = aug,
number = {8},
pages = {3236--3243},
publisher = {American Chemical Society},
title = {{pyProCT: Automated Cluster Analysis for Structural Bioinformatics}},
url = {http://dx.doi.org/10.1021/ct500306s},
volume = {10},
year = {2014}
}
@article{Kupski2015,
abstract = {This work aimed to establish an innovative approach to evaluate the effect of cereals composition on ochratoxin A extraction by multivariate analysis. Principal components analysis was applied to identify the effect of major matrix components on the recovery of ochratoxin A by QuEChERS method using HPTLC and HPLC, and to validate the method for ochratoxin A determination in wheat flour by HPLC. The matrices rice bran, wheat bran and wheat flour were characterized for their physical and chemical attributes. The ochratoxin A recovery in these matrices was highly influenced (R = 0.99) by the sugar content of the matrix, while the lipids content showed a minor interference (R = 0.29). From these data, the QuEChERS method was standardized for extracting ochratoxin A from flour using 1\% ACN:water (2:1) as extraction solvent and dried magnesium sulfate and sodium chloride as salts. The recovery values ranged from 97.6\% to 105\%. The validated method was applied to evaluate natural occurrence of ochratoxin A in 20 wheat flour samples, which were contaminated with ochratoxin A levels in the range of 0.22-0.85 $\mu$g kg-1.},
author = {Kupski, L. and Badiale-Furlong, E.},
doi = {10.1016/j.foodchem.2015.01.005},
issn = {03088146},
journal = {Food Chemistry},
keywords = {Ochratoxin,PCA,QuEChERS,Validation,Wheat flour},
month = jun,
pages = {354--360},
publisher = {Elsevier Ltd},
title = {{Principal components analysis: An innovative approach to establish interferences in ochratoxin A detection}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84921677533\&partnerID=tZOtx3y1},
volume = {177},
year = {2015}
}
@book{Laney,
author = {Laney, Douglas},
publisher = {Gartner},
title = {{The Importance of 'Big Data': A Definition}},
url = {http://www.gartner.com/resId=2057415}
}
@article{Lanl,
author = {Lanl, Patrick Mccormick and Snl, Richard Barrett and Llnl, Bronis De Supinski and Llnl, Evi Dube and Snl, Carter Edwards and Lanl, Paul Henning and Llnl, Steve Langer and Lanl, Allen Mcpherson},
file = {:home/kurtz/Documents/Mendeley/exascale-pmWG.pdf:pdf},
number = {Mimd},
pages = {1--3},
title = {{Programming Models}}
}
@article{Lordan2013,
abstract = {The rise of virtualized and distributed infrastructures has led to new challenges to accomplish the effective use of compute resources through the design and orchestration of distributed applications. As legacy, monolithic applications are replaced with service-oriented applications, questions arise about the steps to be taken in order to maximize the usefulness of the infrastructures and to provide users with tools for the development and execution of distributed applications. One of the issues to be solved is the existence of multiple cloud solutions that are not interoperable, which forces the user to be locked to a specific provider or to continuously adapt applications. With the objective of simplifying the programmers challenges, ServiceSs provides a straightforward programming model and an execution framework that helps on abstracting applications from the actual execution environment. This paper presents how ServiceSs transparently interoperates with multiple providers implementing the appropriate interfaces to execute scientific applications on federated clouds. © 2013 Springer Science+Business Media Dordrecht.},
author = {Lordan, Francesc and Tejedor, Enric and Ejarque, Jorge and Rafanell, Roger and \'{A}lvarez, Javier and Marozzo, Fabrizio and Lezzi, Daniele and Sirvent, Ra\"{u}l and Talia, Domenico and Badia, Rosa M.},
doi = {10.1007/s10723-013-9272-5},
file = {:home/kurtz/Documents/Mendeley/compss\_interop.pdf:pdf},
isbn = {1072301392725},
issn = {1570-7873},
journal = {Journal of Grid Computing},
keywords = {Cloud computing,Interoperability,Programming models,Standards},
number = {1},
pages = {67--91},
title = {{ServiceSs: An Interoperable Programming Framework for the Cloud}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84899458983\&partnerID=tZOtx3y1},
volume = {12},
year = {2013}
}
@article{Muller2014,
abstract = {Market segmentation is a very popular marketing tool. In the food sector, the characteristics of different consumer attitudes and consumption habits are often used as the basis for segmentation. However, the success of a target-oriented marketing approach to selected groups of consumers depends on the results of the methodology applied. So far, relatively little attention has been paid to the reliability of the analysis used for attitude-based market segmentation, to the validity or internal stability of results or to the dynamic stability over time with regard to number, size and properties of the segments. In our study, we used data from a panel of more than 10,000 German households. The participants were segmented using a statement battery and the application of cluster analysis. In order to ensure an internally stable cluster solution, our focus was on the analytical and technical process of decision making when clustering a large dataset. A combination of various statistical measures was applied in order to enable objective decision making in the determination of the optimal number of clusters. The dynamic stability of the resulting segments was determined by confirmatory cluster analyses using data from the same individuals in three subsequent years.The results of the analyses show that neither the internal nor the dynamic stability of market segments should be taken for granted. Therefore, marketers face the challenge of designing segment-specific marketing strategies in a way that allows changes in consumer preferences to be integrated. © 2014 Elsevier Ltd.},
author = {M\"{u}ller, Henriette and Hamm, Ulrich},
doi = {10.1016/j.foodqual.2013.12.004},
issn = {09503293},
journal = {Food Quality and Preference},
keywords = {Cluster analysis,Market segmentation,Panel survey,Reliability,Stability over time,Validity},
month = jun,
pages = {70--78},
title = {{Stability of market segmentation with cluster analysis – A methodological approach}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893387631\&partnerID=tZOtx3y1},
volume = {34},
year = {2014}
}
@book{Nayak2015,
abstract = {Data Clustering platform is used to identify hidden homogeneous clusters of objects to analyze heterogeneous data sets based upon the attribute values in the domain of Information Retrieval, Text Mining, Web Analysis, Computational Biology and Others. In this work, a hybrid clustering algorithm for K-Means called Optimized K-Means with firefly and canopies, has been proposed by integration of two meta-heuristic algorithms: Firefly algorithm and Canopy pre-clustering algorithm. The result model has been applied for classification of breast cancer data. Haberman’s survival dataset from UCI machine learning repository is used as the benchmark dataset for evaluating the performance of the proposed integrated clustering framework. The experimental result shows that the proposed optimized KMeans with firefly and canopies model outperforms traditional K-Means algorithm in terms of classification accuracy and therefore can be used for better breast cancer diagnosis.},
address = {New Delhi},
author = {Nayak, S. and Panda, C. and Xalxo, Z. and Behera, H. S.},
booktitle = {Smart Innovation, Systems and Technologies},
doi = {10.1007/978-81-322-2208-8},
editor = {Jain, Lakhmi C. and Behera, Himansu Sekhar and Mandal, Jyotsna Kumar and Mohapatra, Durga Prasad},
isbn = {978-81-322-2207-1},
issn = {21903026},
keywords = {Breast cancer,Canopy pre-clustering algorithm,Classification,Firefly algorithm,K-means,Medical data},
pages = {333--343},
publisher = {Springer India},
series = {Smart Innovation, Systems and Technologies},
title = {{Computational Intelligence in Data Mining - Volume 2}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84917674265\&partnerID=tZOtx3y1},
volume = {32},
year = {2015}
}
@book{Nixon1995,
abstract = {This volume contains papers presented at the 18th meeting of the World Occam and Transputer User Group (Wotug). The papers cover a wide range of transputer and OCCAM-related topics, such as the the porting and development of the OCCAM language (highlighting the need for cross platform implementations of OCCAM compilers), design approaches and applications.},
author = {Nixon, Patrick},
isbn = {905199222X},
pages = {253},
publisher = {IOS Press},
title = {{Transputer and Occam Developments}},
url = {https://books.google.com/books?hl=en\&lr=\&id=PRu\_G9PMlJUC\&pgis=1},
year = {1995}
}
@article{Tejedor2015,
abstract = {The use of the Python programming language for scientific computing has been gaining momentum in the last years. The fact that it is compact and readable and its complete set of scientific libraries are two important characteristics that favour its adoption. Nevertheless, Python still lacks a solution for easily parallelizing generic scripts on distributed infrastructures, since the current alternatives mostly require the use of APIs for message passing or are restricted to embarrassingly parallel computations. In that sense, this paper presents PyCOMPSs, a framework that facilitates the development of parallel computational workflows in Python. In this approach, the user programs her script in a sequential fashion and decorates the functions to be run as asynchronous parallel tasks. A runtime system is in charge of exploiting the inherent concurrency of the script, detecting the data dependencies between tasks and spawning them to the available resources. Furthermore, we show how this programming model can be built on top of a Big Data storage architecture, where the data stored in the backend is abstracted and accessed from the application in the form of persistent objects.},
author = {Tejedor, E. and Becerra, Y. and Alomar, G. and Queralt, A. and Badia, R. M. and Torres, J. and Cortes, T. and Labarta, J.},
doi = {10.1177/1094342015594678},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = aug,
title = {{PyCOMPSs: Parallel computational workflows in Python}},
url = {http://hpc.sagepub.com/content/early/2015/08/19/1094342015594678.abstract},
year = {2015}
}
@article{Pillet1991,
author = {{Vincent Pillet, Vincent Pillet, Jes\'{u}s Labarta, Toni Cortes, Toni Cortes, Sergi Girona, Sergi Girona}, Departament D'arquitectura De Computadors},
journal = {In WoTUG-18},
title = {{PARAVER: A Tool to Visualize and Analyze Parallel Code}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.1277},
year = {1991}
}
@article{Zelnik-manor2004,
abstract = {We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We first propose that a ‘local ’ scale should be used to compute the affinity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the final randomly initialized k-means stage is eliminated. 1},
author = {Zelnik-manor, Lihi and Zelnik-manor, Lihi and Perona, Pietro and Perona, Pietro},
doi = {10.1.1.84.7940},
file = {:home/kurtz/Documents/Mendeley/NIPS2005\_572.pdf:pdf},
isbn = {9780769535081},
journal = {Advances in Neural Information Processing Systems 17},
pages = {1601--1608},
title = {{Self-tuning spectral clustering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.7940},
volume = {2},
year = {2004}
}
@article{Zeng2007,
abstract = {Background: Flow cytometry produces large multi-dimensional datasets of the physical and molecular characteristics of individual cells. The objective of this study was to simplify the cytometry datasets by arranging or clustering "objects" (cells) into a smaller number of relatively homogeneous groups (clusters) on the basis of interobject similarities and dissimilarities. Results: The algorithm was designed to be driven by histogram features; that is, the relevant single parameter histogram features were used to guide multidimensional k-means clustering without an a priori estimate of cluster number. To test this approach, we simulated cell-derived datasets using protein-coated microspheres (artificial "cells"). The microspheres were constructed to provide 119 populations in 40 samples. The feature-guided (FG) approach accurately identified 100\% of the predetermined cluster combinations. In contrast, an approach based on the partition index (PI) cluster validity measure accurately identified 83.2\% of the clusters. Direct comparisons of the two methods indicated that the FG method was significantly more accurate than PI in identifying both the number of clusters and the number of objects within the clusters (p < .0001). Conclusion: We conclude that parameter feature analysis can be used to effectively guide k-means clustering of flow cytometry datasets. © 2006 Elsevier Inc. All rights reserved.},
author = {Zeng, Qing T. and Pratt, Juan Pablo and Pak, Jane and Ravnic, Dino and Huss, Harold and Mentzer, Steven J.},
doi = {10.1016/j.jbi.2006.06.005},
file = {:home/kurtz/Documents/Mendeley/1-s2.0-S1532046406000669-main.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Clustering,Flow cytometry,Kernel smoothing,Microspheres},
number = {3},
pages = {325--331},
pmid = {16901761},
title = {{Feature-guided clustering of multi-dimensional flow cytometry datasets}},
volume = {40},
year = {2007}
}
