\chapter{Conclusion}


We have been able to parallelize pyProCT with the pyCOMPSs framework. On large datasets, we have seen that the performance is improved. On smaller inputs it is not worth to use it due to all the complex initialization process performed by the framework. Because of that we deem a good decision to have added pyCOMPSs to pyProCT's schedulers, instead of substituting them, leaving to the user the decision of which fits best its datasets. Despite that, the performance could be further increased by defining as tasks the algorithm's and analysis' classes themselves instead of using the wrapper method. This would require to duplicate all code for the algorithms and analysis in order to support the other schedulers.

Thanks to running over multiple nodes now the program can overcome memory problems. However performance is limited by the slowest algorithms no matter how many resources are assigned to it. PyCOMPSs is now offering the ability to define the required resources for a task. This could allow to parallelize that slower algorithms inside the tasks thus reducing that bottleneck. 

This work has revealed some of pyProCT and pyCOMPSs issues. The clustering program is heavily limited by the slowest algorithms and the computation of the initial matrix. Future improvements should be focused on addressing this two sections of the pipeline. On the other hand, pyCOMPSs framework transfer of the matrix data could be improved. Currently they are working with memory-level transfer methods which could greatly enhance this transfers. The inability to serialize some classes' instances is also something to be improved because it requires work-arounds (such as the wrappers) that add too complexity to the simple and clear programming model and usage of pyCOMPSs.

To sum up, pyProCT is now faster and offers all pyCOMPSs tools to analyse code and executions. The way it was refactored makes that if more algorithms are added the performance will be further increased. Aso pyCOMPSs is actively under development so new useful features and performance improvements will be presented and pyProCT will benefit from them without requiring modifications, or maybe small ones, at all. The work done has also posed new research lines for both the framework and the clustering tool through the application and analysis of both to real world cases.



