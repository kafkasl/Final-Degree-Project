\chapter{Results}


This section describes the results of the refactor described in the previous section. 

\section{Programming Model}

COMPSs programming model aims to ease the development and execution of applications. In this section I will evaluate these goals.

First I will talk about the code refactor. As stated in \ref{subsec:pycompss} pyCOMPSs I tried to reduce the code to keep it simple. COMPSs is designed for people without parallelization knowledge, and thus, for sequential programs. I wanted to exploit the simplicity of COMPSs. In order to do it I emulated the process of writing the code directly for pyCOMPSs from a sequential program. This is the scenario I will first analyze.

When talking about the complexity of a program one the first questions is about the code's size. Figure \ref{tab:sizes} shows the comparison between the duplicated classes (the ones used on the original schedulers and the modified versions used when pyCOMPSs scheduler is selected). I compare number of characters and lines because python conventions encourage the usage of line breaks so the results could be misleading (some functions have one parameter per line).


\begin{center}
	\begin{tabular}{| R{6cm} | L{3cm} | L{3cm} |}
		\hline
		Class Name & Original & pyCOMPSs \\ 
		\hline
		\hline
		Driver & 169 / 8180  &  165 / 7911 \\
		\hline
		ClusteringProtocol & 78 / 3703 & 73 / 3490 \\
		\hline
		PostProcessingDriver & 32 / 1531 & 56 / 2700 \\
		\hline
		ClusteringExplorer & 195 / 8470 & 197 / 9226 \\ 
		\hline
	\end{tabular}
	\captionof{table}{Size comparison of duplicated classes} 
	\label{tab:sizes}
\end{center}


Python is a language designed to be easy to read with strong coding conventions so I did not try to minimize the code. I coded in a normal fashion trying to make things clear. Bearing this in mind we see that the refactor did not add too much space. The driver and protocol classes are in fact shorter. This is caused because of the removal of the task-adding loop and the pyScheduler initialization. Postprocessing driver is longer due to the fact that on the original version this section is not parallel. The other ones are quite even.

pyCOMPSs framework just uses python decorators and API calls so, why do we observe a size increase in some classes? This is due to the fact that our data can not automatically serialized by python's pickle. Almost all the extra size is linked to the work needed to handle the matrix data. However, other than adding this little size overhead, the code is much cleaner and easy to read. 


Another important aspect is the execution process and tools offered by the framework. It is here were COMPSs truly shines. 

The level of hardware abstraction provided by the framework is really good. To execute pyProCT in a local environment one just needs to provide the language (python on this case), classpath, executable and parameters. If the user desires to customize the framework offers two kind of hardware configurations. On the one hand we find the \textit{resources.xml}. This file allows to define the workers to be used. This includes supercomputer nodes, cloud services, remote images and more. On the other hand we have the \textit{project.xml} which selects which of the defined resources are to be actually used and some runtime parameters. 

With this simple two files we can define a wide range of available resources to be used and then select which ones we want to use for an specific execution. Thanks to this we can use a lot of different resources without worrying about the internals and communications. COMPSs' already implements all the connectors required to use them so we just need to give a description of them, select which to use and decorate our code. 

For MareNostrum III executions this process is even easier. The development team has created an script to specifically submit jobs to the supercomputer. By default, it requires the same parameters as a normal execution. However, it has a wide range of easy-to-use options with a clear description. With all the parameters available, such as the network and file system to be used or the number of nodes, it automatically creates the \textit{resources.xml} and \textit{project.xml} that best suit our needs. 

This is tools are really useful. Most of the work time working of this project has been spent on trying to execute the program on the supercomputer. One needs to understand how a submission queue system works, which parameters need to be specified, how the class paths are read and used, which way the supercomputer access files, which kind of problems may arise from mutex access to the datasets and so on. This is a quite daunting task for someone without advanced knowledge on the subject or with no one to ask help to. As stated, COMPSs required number of parameters are far less. Understanding some of the aforementioned things will help the user to better use the framework but they are not really mandatory because the COMPSs manuals are good and clear. Following the examples is enough to execute your own programs. 




\section{Performance}


COMPSs is designed to harness all the power of supercomputers and use all the available computing resources. The whole initialization of such a framework is not a trivial matter and because of that I expect it to be slow with respect to MPI or OpenMP. However, being designed to run programs with humongous datasets and computation times, this initial overhead is negligible. I expect to see that MPI and multiprocessing schedulers are faster than pyCOMPSs on small datasets and slower on larger ones. 





\section{Miscellaneous}